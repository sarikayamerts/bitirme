list(fit, ourRPS, preds)
fit
### clears the environment
rm(list = ls())
if (grepl("mert", toString(getwd()))){
setwd("/Users/mertsarikaya/bitirme/")
}
if (grepl("Hp", toString(getwd()))) {
setwd("C:/Users/Hp/Desktop/Bitirme/bitirme")
}
#buraya sizin wd'ye özel bir string yazıp github reposunun directory'sini koyarsınız
if (grepl("mustafa", toString(getwd()))) {
setwd()
}
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
#library(plotly)
library(stats)
#library(PMCMR)
library(caret)
library(e1071)
library(rpart)
library(gbm)
library(plyr)
################################################
# implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
################################################
source("rps.R")
################################################
# converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
################################################
source("converter.R")
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
# 6 - details_change
# functions
# 1 - inverse
# 2 - over_under
# 3 - season_calc
# 4 - set_directory
# 5 - winner
################################################
source("get_dataframes.R")
source("comparison.R")
### converting odds to basic and shin probabilities, gives insiders
source("convert_odds.R")
################  NOT FOR MODELS ##############
### calculate RPS for all matches using Basic and Shin probs
# lastrps <<<< required for models
source("calculate_rps.R")
### reshaping features to create train_features
source("reshape.R")
#we will do widening inside of our model prepration
#last:           matchId, bookmaker, oddtype, shin_prob
#lastrps:        matchId, bookmaker, shin_prob(1X2), winner, season, week, shinrps
#insider:        matchId, bookmaker, z
#details_change: matchId, bookmaker, oddtype, diff, winner, avg
#shin_insider:   matchId, bookmaker, shin_prob(1X2), winner, z
#shin_changes:   matchId, bookmaker, winner, shin_prob(1X2), avg(1X2)
#shin_changes_insider: matchId, bookmaker, winner, shin_prob(1X2), avg(1X2), z
shin <- lastrps[,-c("Shin_RPS")]
shin_insider <- merge(shin, insider, by = c("matchId", "bookmaker"))
shin_changes <- merge(last, details_change[,c("matchId", "bookmaker", "oddtype", "avg", "winner")],by = c("matchId", "bookmaker", "oddtype"))
shin_changes <- reshape(shin_changes, idvar = c("matchId", "bookmaker", "winner"), timevar = c("oddtype"), direction = "wide")
shin_changes_insider <- merge(shin_changes, insider, by = c("matchId", "bookmaker"))
source("train_models.R")
matches_df = matches[week == 43][season == '2018-2019']
details_df = shin
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
if (all(is.na(test_data$winner))){
wide_test <- subsetBookies(bookiesToKeep, last[matchId %in% test_match_ids])
wide_test <- reshape(wide_test, idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_test <- reshape(wide_test, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_test$winner <- NA
}
if (!all(is.na(test_data$winner))){
wide_test <- widening_withwinner(test_data, bookiesToKeep)
wide_test <- wide_test[complete.cases(wide_test)]
}
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
prev_date <- 365
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
fit <- gradient_boosting(train, test, wide_test)
fit
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
if (all(is.na(test_data$winner))){
wide_test <- subsetBookies(bookiesToKeep, last[matchId %in% test_match_ids])
wide_test <- reshape(wide_test, idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_test <- reshape(wide_test, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_test$winner <- NA
}
if (!all(is.na(test_data$winner))){
wide_test <- widening_withwinner(test_data, bookiesToKeep)
wide_test <- wide_test[complete.cases(wide_test)]
}
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
prev_date <- 365
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = T,
summaryFunction = rpsCaret)
tune_Grid <-  expand.grid(interaction.depth = c(1,3,5),
n.trees = (1:10)*50,
shrinkage = c(0.01, 0.05, 0.1, 0.15),
n.minobsinnode = c(5,10))
plot(tune_Grid)
#plot(tune_Grid) #Error in plot.new() : figure margins too large
#plot(gbmFit, plotType = "level")
set.seed(1234)
fit <- train(winner ~ .,
data = train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = tune_Grid)
tune_Grid <-  expand.grid(interaction.depth = c(1,3,5),
n.trees = (1:10)*50,
shrinkage = c(0.01, 0.05, 0.1),
n.minobsinnode = c(5,10))
#plot(tune_Grid) #Error in plot.new() : figure margins too large
#plot(gbmFit, plotType = "level")
set.seed(1234)
fit <- train(winner ~ .,
data = train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = tune_Grid)
fit
output_prob <- predict(fit, test, "prob")
output_prob
#colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = TRUE)
matches_df = matches[week == 42][season == '2018-2019']
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
if (all(is.na(test_data$winner))){
wide_test <- subsetBookies(bookiesToKeep, last[matchId %in% test_match_ids])
wide_test <- reshape(wide_test, idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_test <- reshape(wide_test, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_test$winner <- NA
}
if (!all(is.na(test_data$winner))){
wide_test <- widening_withwinner(test_data, bookiesToKeep)
wide_test <- wide_test[complete.cases(wide_test)]
}
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
prev_date <- 365
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
fit <- gradient_boosting(train, test, wide_test)
fit
lastrps[matchId == "ptvfmjR0"]
ourRPS <- mean(fit[[2]]$RPS)
preds <- fit[[2]]
fit <- fit[[1]]
week_number <- unique(matches_df$week)
if (length(week_number) > 1) {week_number <- paste(length(week_number), "weeks")}
season_number <- unique(matches_df$season)
test_size <- nrow(matches_df)
current_time <- format(Sys.time(), "%Y-%m-%d %X")
if(any(grepl('avg', colnames(details_df)))){
if ("z" %in% colnames(details_df)){feature <- "A+B+C"}
if (!"z" %in% colnames(details_df)){feature <- "A+C"}
}
if (!(any(grepl('avg', colnames(details_df)))) & ("z" %in% colnames(details_df))) {feature <- "A+B"}
if (!(any(grepl('avg', colnames(details_df)))) & !("z" %in% colnames(details_df))) {feature <- "A"}
str = ""
for (i in 1:ncol(fit$bestTune)) {
str <- paste(str, names(fit$bestTune[i]), fit$bestTune[i][1,])
}
fit
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
search = "grid",
classProbs = TRUE,
summaryFunction = rpsCaret)
tunegrid <- expand.grid(.mtry= 1 + (0:14) * 0.5)
fit <- train(winner~.,
data=train,
method="rf",
tuneGrid=tunegrid,
trControl=control,
ntree = 2000,
importance = T)
fit
dim(train)
ourRPS <- mean(fit[[2]]$RPS)
fit
output_prob <- predict(fit, test, "prob")
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = FALSE)
output_prob
output_prob
mean(output_prob$RPS)
fit <- train(winner~.,
data=train,
method="rf",
tuneGrid=tunegrid,
trControl=control,
importance = T)
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
search = "grid",
classProbs = TRUE,
summaryFunction = rpsCaret)
tunegrid <- expand.grid(.mtry= sqrt(ncol(train)))
fit <- train(winner~.,
data=train,
method="rf",
tuneGrid=tunegrid,
trControl=control,
importance = T)
fit
output_prob <- predict(fit, test, "prob")
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = FALSE)
output_prob
output_prob
mean(output_prob$RPS)
fit
fit$method
fit$results
(3:8)
### clears the environment
rm(list = ls())
matches[week > 42][week < 48]
source('~/bitirme/project.R')
a <- read_csv("summary2.csv")
a <- data.table(a)
View(a)
matches_df = matches[week == 42][season == '2018-2019']
details_df = shin
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
if (all(is.na(test_data$winner))){
wide_test <- subsetBookies(bookiesToKeep, last[matchId %in% test_match_ids])
wide_test <- reshape(wide_test, idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_test <- reshape(wide_test, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_test$winner <- NA
}
if (!all(is.na(test_data$winner))){
wide_test <- widening_withwinner(test_data, bookiesToKeep)
wide_test <- wide_test[complete.cases(wide_test)]
}
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
prev_date <- 365
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
alpha=1
nlambda=50
nofReplications=2
trace=F
nFolds=10
set.seed(1234)
train$winner <- convert(train$winner)
train_class <- as.numeric(train$winner)
train <- train[,-c("winner")]
if (max) {
glm_train_data$max <- do.call(pmax, glm_train_data)
glm_test_data$max <- do.call(pmax, glm_test_data)
}
if(tune_lambda){
# to set lambda parameter, cross-validation will be performed and lambda is selected based on RPS performance
cvindices <- generateCVRuns(train_class,nofReplications,nFolds,stratified=TRUE)
# first get lambda sequence for all data
glmnet_alldata <- glmnet(as.matrix(train), as.factor(train_class), family="multinomial", alpha = alpha, nlambda=nlambda)
lambda_sequence <- glmnet_alldata$lambda
cvresult=vector('list',nofReplications*nFolds)
iter=1
for(i in 1:nofReplications) {
thisReplication=cvindices[[i]]
for(j in 1:nFolds){
if(trace){
cat(sprintf('Iteration %d: Fold %d of Replication %d\n',iter,j,i))
}
testindices <- order(thisReplication[[j]])
cvtrain <- train[-testindices]
cvtrainclass <- train_class[-testindices]
cvtest <- train[testindices]
cvtestclass <- train_class[testindices]
inner_cv_glmnet_fit <- glmnet(data.matrix(cvtrain),as.factor(cvtrainclass),family="multinomial", alpha = alpha,lambda=lambda_sequence)
valid_pred <- predict(inner_cv_glmnet_fit, data.matrix(cvtest), s = lambda_sequence, type = "response")
#check order of predictions
order_of_class <- attr(valid_pred,'dimnames')[[2]]
new_order <- c(which(order_of_class=='1'),which(order_of_class=='2'),which(order_of_class=='3'))
foldresult <- rbindlist(lapply(c(1:length(lambda_sequence)),function(x) { data.table(repl=i,fold=j,lambda=lambda_sequence[x],valid_pred[,new_order,x],result=cvtestclass)}))
cvresult[[iter]]=foldresult
iter=iter+1
}
}
cvresult <- rbindlist(cvresult)
cvresult$result <- convert(cvresult$result)
names(cvresult) <- c("repl", "fold", "lambda", "odd1", "oddX", "odd2", "result")
# creating actual targets for rps calculations
cvresult[,pred_id:=1:.N]
outcome_for_rps <- data.table::dcast(cvresult,pred_id~result,value.var='pred_id')
outcome_for_rps[,pred_id:=NULL]
outcome_for_rps[is.na(outcome_for_rps)]=0
outcome_for_rps[outcome_for_rps>0]=1
setcolorder(outcome_for_rps, c("odd1", "oddX", "odd2"))
# calculate RPS
cvresult <- cvresult[, RPS := calculate_rps(odd1, oddX, odd2, result), by = 1:nrow(cvresult)]
overall_results <- data.table(cvresult[,list(repl,fold,lambda,RPS)])
# summarize performance for each lambda
overall_results_summary <- overall_results[,list(RPS=mean(RPS)),list(repl,fold,lambda)]
# find best lambdas as in glmnet based on RPS
overall_results_summary <- overall_results_summary[,list(meanRPS=mean(RPS),sdRPS=sd(RPS)),list(lambda)]
overall_results_summary[,RPS_mean_lb := meanRPS - sdRPS]
overall_results_summary[,RPS_mean_ub := meanRPS + sdRPS]
cv_lambda_min <- overall_results_summary[which.min(meanRPS)]$lambda
semin <- overall_results_summary[lambda==cv_lambda_min]$RPS_mean_ub
cv_lambda.1se <- max(overall_results_summary[meanRPS<semin]$lambda)
cvResultsSummary = list(lambda.min =cv_lambda_min, lambda.1se = cv_lambda.1se,
meanRPS_min=overall_results_summary[lambda==cv_lambda_min]$meanRPS,
meanRPS_1se=overall_results_summary[lambda==cv_lambda.1se]$meanRPS)
}
tune_lambda=T
if(tune_lambda){
# to set lambda parameter, cross-validation will be performed and lambda is selected based on RPS performance
cvindices <- generateCVRuns(train_class,nofReplications,nFolds,stratified=TRUE)
# first get lambda sequence for all data
glmnet_alldata <- glmnet(as.matrix(train), as.factor(train_class), family="multinomial", alpha = alpha, nlambda=nlambda)
lambda_sequence <- glmnet_alldata$lambda
cvresult=vector('list',nofReplications*nFolds)
iter=1
for(i in 1:nofReplications) {
thisReplication=cvindices[[i]]
for(j in 1:nFolds){
if(trace){
cat(sprintf('Iteration %d: Fold %d of Replication %d\n',iter,j,i))
}
testindices <- order(thisReplication[[j]])
cvtrain <- train[-testindices]
cvtrainclass <- train_class[-testindices]
cvtest <- train[testindices]
cvtestclass <- train_class[testindices]
inner_cv_glmnet_fit <- glmnet(data.matrix(cvtrain),as.factor(cvtrainclass),family="multinomial", alpha = alpha,lambda=lambda_sequence)
valid_pred <- predict(inner_cv_glmnet_fit, data.matrix(cvtest), s = lambda_sequence, type = "response")
#check order of predictions
order_of_class <- attr(valid_pred,'dimnames')[[2]]
new_order <- c(which(order_of_class=='1'),which(order_of_class=='2'),which(order_of_class=='3'))
foldresult <- rbindlist(lapply(c(1:length(lambda_sequence)),function(x) { data.table(repl=i,fold=j,lambda=lambda_sequence[x],valid_pred[,new_order,x],result=cvtestclass)}))
cvresult[[iter]]=foldresult
iter=iter+1
}
}
cvresult <- rbindlist(cvresult)
cvresult$result <- convert(cvresult$result)
names(cvresult) <- c("repl", "fold", "lambda", "odd1", "oddX", "odd2", "result")
# creating actual targets for rps calculations
cvresult[,pred_id:=1:.N]
outcome_for_rps <- data.table::dcast(cvresult,pred_id~result,value.var='pred_id')
outcome_for_rps[,pred_id:=NULL]
outcome_for_rps[is.na(outcome_for_rps)]=0
outcome_for_rps[outcome_for_rps>0]=1
setcolorder(outcome_for_rps, c("odd1", "oddX", "odd2"))
# calculate RPS
cvresult <- cvresult[, RPS := calculate_rps(odd1, oddX, odd2, result), by = 1:nrow(cvresult)]
overall_results <- data.table(cvresult[,list(repl,fold,lambda,RPS)])
# summarize performance for each lambda
overall_results_summary <- overall_results[,list(RPS=mean(RPS)),list(repl,fold,lambda)]
# find best lambdas as in glmnet based on RPS
overall_results_summary <- overall_results_summary[,list(meanRPS=mean(RPS),sdRPS=sd(RPS)),list(lambda)]
overall_results_summary[,RPS_mean_lb := meanRPS - sdRPS]
overall_results_summary[,RPS_mean_ub := meanRPS + sdRPS]
cv_lambda_min <- overall_results_summary[which.min(meanRPS)]$lambda
semin <- overall_results_summary[lambda==cv_lambda_min]$RPS_mean_ub
cv_lambda.1se <- max(overall_results_summary[meanRPS<semin]$lambda)
cvResultsSummary = list(lambda.min =cv_lambda_min, lambda.1se = cv_lambda.1se,
meanRPS_min=overall_results_summary[lambda==cv_lambda_min]$meanRPS,
meanRPS_1se=overall_results_summary[lambda==cv_lambda.1se]$meanRPS)
}
cvresult <- rbindlist(cvresult)
cvresult
cvResultsSummary
fit <- glmnet(as.matrix(train),as.factor(train_class),family="multinomial", alpha = alpha,lambda=cvResultsSummary$lambda.min)
fit
predicted_probabilities <- predict(fit, as.matrix(test), type = "response")
output_prob <- data.table(predicted_probabilities[,,])
output_prob
output_prob <- data.table(predicted_probabilities[,,])
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
fit
fit$a0
fit$beta
fit$lambda
fit$call
alpha
data.frame(lambda = fit$lambda)
fit$bestTune <- data.frame(lambda = fit$lambda)
fit
fit$bestTune
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
prev_date <- 365
lower_date <- as.Date(min_date) - prev_date
lower_date
min_date
str(min_date)
toString(min_date)
print(min_date)
data.frame(Date = min_date)
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
if (all(is.na(test_data$winner))){
wide_test <- subsetBookies(bookiesToKeep, last[matchId %in% test_match_ids])
wide_test <- reshape(wide_test, idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_test <- reshape(wide_test, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_test$winner <- NA
}
if (!all(is.na(test_data$winner))){
wide_test <- widening_withwinner(test_data, bookiesToKeep)
wide_test <- wide_test[complete.cases(wide_test)]
}
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
prev_date <- 365
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
week_number <- unique(matches_df$week)
if (length(week_number) > 1) {week_number <- paste(length(week_number), "weeks")}
season_number <- unique(matches_df$season)
test_size <- nrow(matches_df)
current_time <- format(Sys.time(), "%Y-%m-%d %X")
if(any(grepl('avg', colnames(details_df)))){
if ("z" %in% colnames(details_df)){feature <- "A+B+C"}
if (!"z" %in% colnames(details_df)){feature <- "A+C"}
}
if (!(any(grepl('avg', colnames(details_df)))) & ("z" %in% colnames(details_df))) {feature <- "A+B"}
if (!(any(grepl('avg', colnames(details_df)))) & !("z" %in% colnames(details_df))) {feature <- "A"}
str = ""
for (i in 1:ncol(fit$bestTune)) {
str <- paste(str, names(fit$bestTune[i]), fit$bestTune[i][1,])
}
model_type
model_type = "mrt"
feature
is_ordered
is_ordered = F
week_number
season_number
test_size
lower_date
min_date
ourRPS
ourRPS = 123
str
current_time
data.frame(ModelType = model_type,
Feature = feature,
Ordered = is_ordered,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
TrainStart = lower_date,
TestStart = min_date,
OurRPS = ourRPS,
BestTune = str,
timestamp = current_time)
source('~/bitirme/project.R')
a <- data.table(read_csv("summary2.csv"))
View(a)
source('~/bitirme/project.R')
