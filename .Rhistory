wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
wide_test <- wide_test[complete.cases(wide_test)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
set.seed(1234)
train$winner <- convert(train$winner)
train_class <- as.numeric(train$winner)
train <- train[,-c("winner")]
#adds new column for maximum observation (adds odd1 oddX or odd2)
if (max) {
glm_train_data$max <- do.call(pmax, glm_train_data)
glm_test_data$max <- do.call(pmax, glm_test_data)
}
if(tune_lambda){
# to set lambda parameter, cross-validation will be performed and lambda is selected based on RPS performance
cvindices <- generateCVRuns(train_class,nofReplications,nFolds,stratified=TRUE)
# first get lambda sequence for all data
glmnet_alldata <- glmnet(as.matrix(train), as.factor(train_class), family="multinomial", alpha = alpha, nlambda=nlambda)
lambda_sequence <- glmnet_alldata$lambda
cvresult=vector('list',nofReplications*nFolds)
iter=1
for(i in 1:nofReplications) {
thisReplication=cvindices[[i]]
for(j in 1:nFolds){
if(trace){
cat(sprintf('Iteration %d: Fold %d of Replication %d\n',iter,j,i))
}
testindices <- order(thisReplication[[j]])
cvtrain <- train[-testindices]
cvtrainclass <- train_class[-testindices]
cvtest <- train[testindices]
cvtestclass <- train_class[testindices]
inner_cv_glmnet_fit <- glmnet(data.matrix(cvtrain),as.factor(cvtrainclass),family="multinomial", alpha = alpha,lambda=lambda_sequence)
valid_pred <- predict(inner_cv_glmnet_fit, data.matrix(cvtest), s = lambda_sequence, type = "response")
#check order of predictions
order_of_class <- attr(valid_pred,'dimnames')[[2]]
new_order <- c(which(order_of_class=='1'),which(order_of_class=='2'),which(order_of_class=='3'))
foldresult <- rbindlist(lapply(c(1:length(lambda_sequence)),function(x) { data.table(repl=i,fold=j,lambda=lambda_sequence[x],valid_pred[,new_order,x],result=cvtestclass)}))
cvresult[[iter]]=foldresult
iter=iter+1
}
}
cvresult <- rbindlist(cvresult)
cvresult$result <- convert(cvresult$result)
names(cvresult) <- c("repl", "fold", "lambda", "odd1", "oddX", "odd2", "result")
# creating actual targets for rps calculations
cvresult[,pred_id:=1:.N]
outcome_for_rps <- data.table::dcast(cvresult,pred_id~result,value.var='pred_id')
outcome_for_rps[,pred_id:=NULL]
outcome_for_rps[is.na(outcome_for_rps)]=0
outcome_for_rps[outcome_for_rps>0]=1
setcolorder(outcome_for_rps, c("odd1", "oddX", "odd2"))
# calculate RPS
cvresult <- cvresult[, RPS := calculate_rps(odd1, oddX, odd2, result), by = 1:nrow(cvresult)]
overall_results <- data.table(cvresult[,list(repl,fold,lambda,RPS)])
# summarize performance for each lambda
overall_results_summary <- overall_results[,list(RPS=mean(RPS)),list(repl,fold,lambda)]
# find best lambdas as in glmnet based on RPS
overall_results_summary <- overall_results_summary[,list(meanRPS=mean(RPS),sdRPS=sd(RPS)),list(lambda)]
overall_results_summary[,RPS_mean_lb := meanRPS - sdRPS]
overall_results_summary[,RPS_mean_ub := meanRPS + sdRPS]
cv_lambda_min <- overall_results_summary[which.min(meanRPS)]$lambda
semin <- overall_results_summary[lambda==cv_lambda_min]$RPS_mean_ub
cv_lambda.1se <- max(overall_results_summary[meanRPS<semin]$lambda)
cvResultsSummary = list(lambda.min =cv_lambda_min, lambda.1se = cv_lambda.1se,
meanRPS_min=overall_results_summary[lambda==cv_lambda_min]$meanRPS,
meanRPS_1se=overall_results_summary[lambda==cv_lambda.1se]$meanRPS)
}
final_glmnet_fit <- glmnet(as.matrix(train),as.factor(train_class),family="multinomial", alpha = alpha,lambda=cvResultsSummary$lambda.min)
predicted_probabilities <- predict(final_glmnet_fit, as.matrix(test), type = "response")
output_prob <- data.table(predicted_probabilities[,,])
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$winner <- wide_test$winner
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2", "winner"))
output_prob <- as.data.table(output_prob)[, RPS := calculate_rps(odd1, oddX, odd2, winner), by = 1:nrow(output_prob)]
print(output_prob)
testRPS <- lastrps[matchId %in% wide_test$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
testRPS
testRPS$var
min(testRPS$var)
max(testRPS$var)
testRPS <- lastrps[matchId %in% wide_test$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
min_rps <- min(testRPS$var)
max_rps <- max(testRPS$var)
round(max(testRPS$var),6)
round(max(testRPS$var),7)
min_rps <- round(min(testRPS$var),7)
max_rps <- round(max(testRPS$var),7)
list(min_rps, max_rps)
#train and test are necessary, requires defined lastrps (maybe use only last?)
#returns output_prob, testRPS
random_forest <- function(train, test, wide_test,
control_method = "repeatedcv", control_number = 10, repeat_number = 3,
metric_name = "Accuracy", varimpTF = TRUE, is_ordered = FALSE){
control <- trainControl(method = control_method, number = control_number, repeats = repeat_number)
#metric can be Accuracy, ROC, RMSE, logLoss
set.seed(7)
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry)
if (!is_ordered){rf_default <- train(factor(convert(winner))~., data=train, method="rf", metric=metric_name, tuneGrid=tunegrid, trControl=control, importance = varimpTF)}
else{rf_default <- train(winner~., data=train, method="rf", metric=metric_name, tuneGrid=tunegrid, trControl=control, importance = varimpTF)}
varImp(rf_default)
output_prob <- predict(rf_default, test, "prob")
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$winner <- wide_test$winner
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2", "winner"))
output_prob <- as.data.table(output_prob)[, RPS := calculate_rps(odd1, oddX, odd2, winner), by = 1:nrow(output_prob)]
print(output_prob)
testRPS <- lastrps[matchId %in% wide_test$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
minRPS <- round(min(testRPS$var),7)
maxRPS <- round(max(testRPS$var),7)
ourRPS <- mean(output_prob$RPS)
x <- data.frame("***IE 492***", ourRPS)
names(x) <- names(testRPS)
testRPS <- rbind(testRPS, x)
testRPS <- testRPS[order(testRPS$var),]
print(testRPS)
return(list(ourRPS, minRPS, maxRPS))
}
#trace prints out that sentence
#max includes column for maximum oddtype
train_glmnet <- function(train, test, wide_test,
alpha=1,nlambda=50, tune_lambda=T,nofReplications=2,
nFolds=10,trace=F, max = F){
set.seed(1234)
train$winner <- convert(train$winner)
train_class <- as.numeric(train$winner)
train <- train[,-c("winner")]
#adds new column for maximum observation (adds odd1 oddX or odd2)
if (max) {
glm_train_data$max <- do.call(pmax, glm_train_data)
glm_test_data$max <- do.call(pmax, glm_test_data)
}
if(tune_lambda){
# to set lambda parameter, cross-validation will be performed and lambda is selected based on RPS performance
cvindices <- generateCVRuns(train_class,nofReplications,nFolds,stratified=TRUE)
# first get lambda sequence for all data
glmnet_alldata <- glmnet(as.matrix(train), as.factor(train_class), family="multinomial", alpha = alpha, nlambda=nlambda)
lambda_sequence <- glmnet_alldata$lambda
cvresult=vector('list',nofReplications*nFolds)
iter=1
for(i in 1:nofReplications) {
thisReplication=cvindices[[i]]
for(j in 1:nFolds){
if(trace){
cat(sprintf('Iteration %d: Fold %d of Replication %d\n',iter,j,i))
}
testindices <- order(thisReplication[[j]])
cvtrain <- train[-testindices]
cvtrainclass <- train_class[-testindices]
cvtest <- train[testindices]
cvtestclass <- train_class[testindices]
inner_cv_glmnet_fit <- glmnet(data.matrix(cvtrain),as.factor(cvtrainclass),family="multinomial", alpha = alpha,lambda=lambda_sequence)
valid_pred <- predict(inner_cv_glmnet_fit, data.matrix(cvtest), s = lambda_sequence, type = "response")
#check order of predictions
order_of_class <- attr(valid_pred,'dimnames')[[2]]
new_order <- c(which(order_of_class=='1'),which(order_of_class=='2'),which(order_of_class=='3'))
foldresult <- rbindlist(lapply(c(1:length(lambda_sequence)),function(x) { data.table(repl=i,fold=j,lambda=lambda_sequence[x],valid_pred[,new_order,x],result=cvtestclass)}))
cvresult[[iter]]=foldresult
iter=iter+1
}
}
cvresult <- rbindlist(cvresult)
cvresult$result <- convert(cvresult$result)
names(cvresult) <- c("repl", "fold", "lambda", "odd1", "oddX", "odd2", "result")
# creating actual targets for rps calculations
cvresult[,pred_id:=1:.N]
outcome_for_rps <- data.table::dcast(cvresult,pred_id~result,value.var='pred_id')
outcome_for_rps[,pred_id:=NULL]
outcome_for_rps[is.na(outcome_for_rps)]=0
outcome_for_rps[outcome_for_rps>0]=1
setcolorder(outcome_for_rps, c("odd1", "oddX", "odd2"))
# calculate RPS
cvresult <- cvresult[, RPS := calculate_rps(odd1, oddX, odd2, result), by = 1:nrow(cvresult)]
overall_results <- data.table(cvresult[,list(repl,fold,lambda,RPS)])
# summarize performance for each lambda
overall_results_summary <- overall_results[,list(RPS=mean(RPS)),list(repl,fold,lambda)]
# find best lambdas as in glmnet based on RPS
overall_results_summary <- overall_results_summary[,list(meanRPS=mean(RPS),sdRPS=sd(RPS)),list(lambda)]
overall_results_summary[,RPS_mean_lb := meanRPS - sdRPS]
overall_results_summary[,RPS_mean_ub := meanRPS + sdRPS]
cv_lambda_min <- overall_results_summary[which.min(meanRPS)]$lambda
semin <- overall_results_summary[lambda==cv_lambda_min]$RPS_mean_ub
cv_lambda.1se <- max(overall_results_summary[meanRPS<semin]$lambda)
cvResultsSummary = list(lambda.min =cv_lambda_min, lambda.1se = cv_lambda.1se,
meanRPS_min=overall_results_summary[lambda==cv_lambda_min]$meanRPS,
meanRPS_1se=overall_results_summary[lambda==cv_lambda.1se]$meanRPS)
}
final_glmnet_fit <- glmnet(as.matrix(train),as.factor(train_class),family="multinomial", alpha = alpha,lambda=cvResultsSummary$lambda.min)
predicted_probabilities <- predict(final_glmnet_fit, as.matrix(test), type = "response")
output_prob <- data.table(predicted_probabilities[,,])
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$winner <- wide_test$winner
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2", "winner"))
output_prob <- as.data.table(output_prob)[, RPS := calculate_rps(odd1, oddX, odd2, winner), by = 1:nrow(output_prob)]
print(output_prob)
testRPS <- lastrps[matchId %in% wide_test$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
minRPS <- round(min(testRPS$var),7)
maxRPS <- round(max(testRPS$var),7)
ourRPS <- mean(output_prob$RPS)
x <- data.frame("***IE 492***", ourRPS)
names(x) <- names(testRPS)
testRPS <- rbind(testRPS, x)
testRPS <- testRPS[order(testRPS$var),]
print(testRPS)
return(list(ourRPS, minRPS, maxRPS))
}
gradient_boosting <- function(train, test, wide_test){
fitControl <- trainControl(method = "cv", number = 30)
tune_Grid <-  expand.grid(interaction.depth = 5,
n.trees = 1000,
shrinkage = 0.1,
n.minobsinnode = 50)
set.seed(1234)
fit <- train(winner ~ ., data = train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = tune_Grid)
output_prob <- predict(fit,test,type= "prob")
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$winner <- wide_test$winner
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2", "winner"))
output_prob <- as.data.table(output_prob)[, RPS := calculate_rps(odd1, oddX, odd2, winner), by = 1:nrow(output_prob)]
print(output_prob)
testRPS <- lastrps[matchId %in% wide_test$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
minRPS <- round(min(testRPS$var),7)
maxRPS <- round(max(testRPS$var),7)
ourRPS <- mean(output_prob$RPS)
x <- data.frame("***IE 492***", ourRPS)
names(x) <- names(testRPS)
testRPS <- rbind(testRPS, x)
testRPS <- testRPS[order(testRPS$var),]
print(testRPS)
return(list(ourRPS, minRPS, maxRPS))
}
decision_tree <- function(train, test, wide_test){
set.seed(1234)
fit <- rpart(train$winner ~ .,
data = train,
method="class",
control = rpart.control(minsplit = 50, minbucket = 20, cp = 0.01))
output_prob <- data.table(predict(fit,test,type= "prob"))
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$winner <- wide_test$winner
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2", "winner"))
output_prob <- as.data.table(output_prob)[, RPS := calculate_rps(odd1, oddX, odd2, winner), by = 1:nrow(output_prob)]
print(output_prob)
testRPS <- lastrps[matchId %in% wide_test$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
minRPS <- round(min(testRPS$var),7)
maxRPS <- round(max(testRPS$var),7)
ourRPS <- mean(output_prob$RPS)
x <- data.frame("***IE 492***", ourRPS)
names(x) <- names(testRPS)
testRPS <- rbind(testRPS, x)
testRPS <- testRPS[order(testRPS$var),]
print(testRPS)
return(list(ourRPS, minRPS, maxRPS))
}
matches_df = matches[week == 48][season == '2018-2019']
details_df =  lastrps[,-c("Shin_RPS")]
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
#wide_test <- widening(test_data[,-c("norm_prob")], bookiesToKeep)
wide_test <- widening_withwinner(test_data, bookiesToKeep)
min_date <- min(matches[matchId %in% test_match_ids]$date)
#if (length(test_match_ids) < 12) {prev_date = 180}
if (length(test_match_ids) < 30) {prev_date = 400}
if (length(test_match_ids) >= 30) {prev_date = 1000}
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
#train_data <- train_data[!(matchId %in% risky_matches)]
#wide_train <- widening(train_data[,-c("norm_prob")], bookiesToKeep)
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
wide_test <- wide_test[complete.cases(wide_test)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
fit <- decision_tree(train, test, wide_test)
fit
fit[1]
fit[2]
fit[2][[1]]
ourRPS <- fit[1][[1]]
c(fit, model_type, week_number, season_number, test_size, ourRPS, minRPS, maxRPS)
model_type == "decision_tree"
model_type = "decision_tree"
c(model_type, week_number, season_number, test_size, ourRPS, minRPS, maxRPS)
week_number <- unique(matches_df$week)
season_number <- unique(matches_df$season)
test_size <- nrow(matches_df)
ourRPS <- fit[1][[1]]
minRPS <- fit[2][[1]]
maxRPS <- fit[3][[1]]
c(model_type, week_number, season_number, test_size, ourRPS, minRPS, maxRPS)
data.frame(ModelType = model_type,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = MaxRPS)
data.frame(ModelType = model_type,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS)
systemtime()
system.time()
Sys.time()
format(Sys.time(), "%a %b %d %X %Y")
format(Sys.time(), "%Y-%m-%d %X %Y")
format(Sys.time(), "%Y-%m-%d %X")
data.frame(ModelType = model_type,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS,
timestamp = time)
data.frame(ModelType = model_type,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS,
timestamp = time)
data.frame(ModelType = model_type,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS)
time
current_time <- format(Sys.time(), "%Y-%m-%d %X")
data.frame(ModelType = model_type,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS,
timestamp = current_time)
matches[week == 48]
matches[week > 46]
matches_df = matches[week > 46][season == '2018-2019']
details_df =  lastrps[,-c("Shin_RPS")]
details_df
colnames(details_df)
"shin" %in% colnames(details_df)
grepl('shin', colnames(data))
grepl('shin', colnames(details_df))
any(grepl('shin', colnames(details_df)))
details_df = shin_changes_insider
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
#wide_test <- widening(test_data[,-c("norm_prob")], bookiesToKeep)
wide_test <- widening_withwinner(test_data, bookiesToKeep)
min_date <- min(matches[matchId %in% test_match_ids]$date)
#if (length(test_match_ids) < 12) {prev_date = 180}
if (length(test_match_ids) < 30) {prev_date = 400}
if (length(test_match_ids) >= 30) {prev_date = 1000}
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
#train_data <- train_data[!(matchId %in% risky_matches)]
#wide_train <- widening(train_data[,-c("norm_prob")], bookiesToKeep)
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
wide_test <- wide_test[complete.cases(wide_test)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
any(grepl('shin', colnames(details_df)))
any(grepl('z', colnames(details_df)))
colnames(details_df)
"z" %in% colnames(details_df)
any(grepl('avg', colnames(details_df)))
if(any(grepl('avg', colnames(details_df)))){
if ("z" %in% colnames(details_df)){
return("A+B+C")
}
return("A+C")
}
else if ("z" %in% colnames(details_df)) {return("A+B")}
else {return("A")}
matches_df = matches[week == 48][season == '2018-2019']
details_df =  lastrps[,-c("Shin_RPS")]
test_match_ids <- matches_df$matchId
test_data <- details_df[matchId %in% test_match_ids]
#wide_test <- widening(test_data[,-c("norm_prob")], bookiesToKeep)
wide_test <- widening_withwinner(test_data, bookiesToKeep)
min_date <- min(matches[matchId %in% test_match_ids]$date)
#if (length(test_match_ids) < 12) {prev_date = 180}
if (length(test_match_ids) < 30) {prev_date = 400}
if (length(test_match_ids) >= 30) {prev_date = 1000}
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
#train_data <- train_data[!(matchId %in% risky_matches)]
#wide_train <- widening(train_data[,-c("norm_prob")], bookiesToKeep)
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
wide_test <- wide_test[complete.cases(wide_test)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
fit <- decision_tree(train, test, wide_test)
week_number <- unique(matches_df$week)
season_number <- unique(matches_df$season)
test_size <- nrow(matches_df)
ourRPS <- fit[1][[1]]
minRPS <- fit[2][[1]]
maxRPS <- fit[3][[1]]
current_time <- format(Sys.time(), "%Y-%m-%d %X")
if(any(grepl('avg', colnames(details_df)))){
if ("z" %in% colnames(details_df)){
feature <- "A+B+C"
}
feature <- "A+C"
}
if (!(any(grepl('avg', colnames(details_df)))) & ("z" %in% colnames(details_df))) {feature <- "A+B"}
if (!(any(grepl('avg', colnames(details_df)))) & !("z" %in% colnames(details_df))) {feature <- "A"}
feature
data.frame(ModelType = model_type,
Feature = feature,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS,
timestamp = current_time)
df_summary <- data.frame(ModelType = model_type,
Feature = feature,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS,
timestamp = current_time)
write.csv(df_summary, file = "summary.csv", row.names = FALSE, quote = FALSE)
df_prev <- read.csv("summary.csv")
df_prev
rbind(df_prev, df_summary)
df_summary <- rbind(df_summary, df_new)
df_summary <- read.csv("summary.csv")
df_new <- data.frame(ModelType = model_type,
Feature = feature,
Weeks = week_number,
Seasons = season_number,
TestSize = test_size,
OurRPS = ourRPS,
MinRPS = minRPS,
MaxRPS = maxRPS,
timestamp = current_time)
df_summary <- rbind(df_summary, df_new)
df_summary
for (i in c("random_forest", "decision_tree", "glmnet", "gradient_boosting")){
AB <- models(matches_df = matches[week == 48][season == '2018-2019'],
details_df = shin,
model_type = i)
}
read.csv("summary.csv")
source("train_models.R")
for (i in c("random_forest", "decision_tree", "glmnet", "gradient_boosting")){
AB <- models(matches_df = matches[week == 48][season == '2018-2019'],
details_df = shin,
model_type = i)
}
read.csv("summary.csv")
matches_df = matches[week == 48][season == '2018-2019']
AB <- models(matches_df = matches[week == 48][season == '2018-2019'],
details_df = shin_insider,
model_type = i)
AB <- models(matches_df = matches[week == 48][season == '2018-2019'],
details_df = shin_changes,
model_type = i)
AB <- models(matches_df = matches[week == 48][season == '2018-2019'],
details_df = shin_changes_insider,
model_type = i)
read.csv("summary.csv")
ABC_ord <- models(matches_df = matches[week == 47][season == '2018-2019'],
details_df = shin_changes_insider,
model_type = "decision_tree",
ordered = TRUE)
ABC_ord <- models(matches_df = matches[week == 44][season == '2018-2019'],
details_df = shin_changes_insider,
model_type = "decision_tree",
ordered = TRUE)
ABC_ord <- models(matches_df = matches[week == 44][season == '2018-2019'],
details_df = shin_changes_insider,
model_type = "random_forest",
ordered = TRUE)
read.csv("summary.csv")
