CDNOW_master <- read_csv("Downloads/CDNOW_master/CDNOW_master.txt")
View(CDNOW_master)
cdnow <- read.table("Downloads/CDNOW_master/CDNOW_master.txt")
rm(CDNOW_master)
View(cdnow)
cdnow$V1 <- NULL
View(cdnow)
colnames(cdnow) <- c(“ID”, “TARIH”, “ADET”, “FIYAT”)
cdnow <- read.table("Downloads/CDNOW_master/CDNOW_master.txt")
colnames(cdnow) <- c(“ID”, “TARIH”, “ADET”, “FIYAT”)
View(cdnow)
colnames(cdnow) <- c("ID", "TARIH", "ADET", "FIYAT")
View(cdnow)
str(cdnow)
cdnow$ID <- as.factor(as.character(cdnow$ID))
cdnow$TARIH <- as.Date(as.character(cdnow$TARIH), “%Y%m%d”)
cdnow$TARIH <- as.Date(as.character(cdnow$TARIH), "%Y%m%d")
str(cdnow)
refDay <- max(cdnow$TARIH)
class(refDay)
as.numeric(refDay — cdnow$TARIH)
as.numeric(refDay-cdnow$TARIH)
library(dplyr)
rfm_recency <- cdnow %>% group_by(ID) %>% summarise(Recency = as.numeric(refDay)—as.numeric(max(TARIH)))
rfm_recency <- cdnow %>% group_by(ID) %>% summarise(Recency = as.numeric(refDay)—as.numeric(max(TARIH)))
rfm_recency <- cdnow %>% group_by(ID) %>% summarise(Recency = as.numeric(refDay)-as.numeric(max(TARIH)))
View(rfm_recency)
rfm_frequency <- cdnow %>% group_by(ID) %>% summarise(Frequency = n())
View(rfm_frequency)
rfm_monetary <- cdnow %>% group_by(ID) %>% summarise(Monetary = sum(FIYAT))
View(rfm_monetary)
cdnow$ID == 1
cdnow[cdnow$ID == 1]
cdnow[cdnow$ID == 1]
filter(cdnow, ID == 1)
filter(cdnow, ID == 951)
filter(rfm_monetary, ID == 951)
install.packages("mlr")
install.packages("XML")
install.packages("e1071")
install.packages("e1071") --host
config.log
install.packages('e1071', dependencies=TRUE)
install.packages("e1071")
### clears the environment
rm(list = ls())
if (grepl("mert", toString(getwd()))){
setwd("/Users/mertsarikaya/bitirme/")
}
if (grepl("Hp", toString(getwd()))) {
setwd("C:/Users/Hp/Desktop/Bitirme/bitirme")
}
#buraya sizin wd'ye özel bir string yazıp github reposunun directory'sini koyarsınız
if (grepl("mustafa", toString(getwd()))) {
setwd()
}
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
#library(plotly)
library(stats)
#library(PMCMR)
library(caret)
library(e1071)
library(rpart)
library(gbm)
library(plyr)
library(ordinalForest)
################################################
# implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
################################################
source("rps.R")
################################################
# converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
################################################
source("converter.R")
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
# 6 - details_change
# functions
# 1 - inverse
# 2 - over_under
# 3 - season_calc
# 4 - set_directory
# 5 - winner
################################################
source("get_dataframes.R")
source("comparison.R")
### converting odds to basic and shin probabilities, gives insiders
source("convert_odds.R")
################  NOT FOR MODELS ##############
### calculate RPS for all matches using Basic and Shin probs
# lastrps <<<< required for models
source("calculate_rps.R")
### reshaping features to create train_features
source("reshape.R")
#we will do widening inside of our model prepration
#last:           matchId, bookmaker, oddtype, shin_prob
#lastrps:        matchId, bookmaker, shin_prob(1X2), winner, season, week, shinrps
#insider:        matchId, bookmaker, z
#details_change: matchId, bookmaker, oddtype, diff, winner, avg
#shin_insider:   matchId, bookmaker, shin_prob(1X2), winner, z
#shin_changes:   matchId, bookmaker, winner, shin_prob(1X2), avg(1X2)
#shin_changes_insider: matchId, bookmaker, winner, shin_prob(1X2), avg(1X2), z
shin <- lastrps[,-c("Shin_RPS")]
shin_insider <- merge(shin, insider, by = c("matchId", "bookmaker"))
shin_changes <- merge(last, details_change[,c("matchId", "bookmaker", "oddtype", "avg", "winner")],by = c("matchId", "bookmaker", "oddtype"))
shin_changes <- reshape(shin_changes, idvar = c("matchId", "bookmaker", "winner"), timevar = c("oddtype"), direction = "wide")
shin_changes_insider <- merge(shin_changes, insider, by = c("matchId", "bookmaker"))
rpsCaret<- function (data, lev = NULL, model = NULL) {
require(verification)
if (!all(levels(data[, "pred"]) == levels(data[, "obs"])))
stop("levels of observed and predicted data do not match")
rownames(data) <- NULL
obs <- as.vector(as.numeric(data$obs))
pred <- as.matrix(subset(data, select = levels(data$obs)))
rpsObject <- verification::rps(obs, pred)
out<- (-1) * rpsObject$rps
names(out) <- c("rpsScore")
out
}
environment(rpsCaret) <- asNamespace('caret')
matches_df = next_matches[week == 51]
details_df = shin
test_match_ids <- matches_df$matchId
test_match_ids
test_data <- details_df[matchId %in% test_match_ids]
if (all(is.na(test_data$winner))){
wide_test <- subsetBookies(bookiesToKeep, last[matchId %in% test_match_ids])
wide_test <- reshape(wide_test, idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_test <- reshape(wide_test, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_test$winner <- NA
}
if (!all(is.na(test_data$winner))){
wide_test <- widening_withwinner(test_data, bookiesToKeep)
wide_test <- wide_test[complete.cases(wide_test)]
}
min_date <- min(matches_df[matchId %in% test_match_ids]$date)
if(nrow(wide_test) > 40){prev_date <- 1000}
if(nrow(wide_test) <= 40){prev_date <- 365}
lower_date <- as.Date(min_date) - prev_date
train_match_ids <- matches[date < min_date][date > lower_date]$matchId
train_data <- details_df[matchId %in% train_match_ids]
wide_train <- widening_withwinner(train_data, bookiesToKeep)
wide_train <- wide_train[complete.cases(wide_train)]
train <- wide_train[,-c("matchId", "date", "week", "season")]
test <- wide_test[,-c("matchId", "winner", "date", "week", "season")]
train
test
head(train,5)
fit <- train_glmnet(train, test, wide_test)
#train and test are necessary, requires defined lastrps (maybe use only last?)
#returns output_prob, testRPS
random_forest <- function(train, test, wide_test){
set.seed(1234)
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
search = "grid",
classProbs = TRUE,
summaryFunction = rpsCaret)
tunegrid <- expand.grid(.mtry= 4+(0:8)*0.5)
fit <- train(winner~.,
data=train,
method="rf",
tuneGrid=tunegrid,
trControl=control,
importance = T)
output_prob <- predict(fit, test, "prob")
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
return(list(fit, output_prob))
}
ord_rf <- function(train, test, wide_test){
set.seed(1234)
# There are several hyperparameters, which do, however,
# not have to be optimized by the user in general, because the default
# values used for these hyperparameters were seen to be in a reasonable
# range and the results seem to be quite robust with respect to the
# choices of the hyperparameter values.
fit <- ordfor(depvar="winner",
data=train, nsets=1000, ntreeperdiv=400,
ntreefinal=5000, perffunction = "equal")
preds <- predict(fit, newdata=test, "prob")
output_prob <- data.table(preds$classfreqtree)
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
return(list(fit, output_prob))
}
train_glmnet <- function(train, test, wide_test,
alpha=1,nlambda=50, tune_lambda=T,nofReplications=2,
nFolds=10,trace=F, max = F){
set.seed(1234)
train$winner <- convert(train$winner)
train_class <- as.numeric(train$winner)
train <- train[,-c("winner")]
if (max) {
glm_train_data$max <- do.call(pmax, glm_train_data)
glm_test_data$max <- do.call(pmax, glm_test_data)
}
if(tune_lambda){
# to set lambda parameter, cross-validation will be performed and lambda is selected based on RPS performance
cvindices <- generateCVRuns(train_class,nofReplications,nFolds,stratified=TRUE)
# first get lambda sequence for all data
glmnet_alldata <- glmnet(as.matrix(train), as.factor(train_class), family="multinomial", alpha = alpha, nlambda=nlambda)
lambda_sequence <- glmnet_alldata$lambda
cvresult=vector('list',nofReplications*nFolds)
iter=1
for(i in 1:nofReplications) {
thisReplication=cvindices[[i]]
for(j in 1:nFolds){
if(trace){
cat(sprintf('Iteration %d: Fold %d of Replication %d\n',iter,j,i))
}
testindices <- order(thisReplication[[j]])
cvtrain <- train[-testindices]
cvtrainclass <- train_class[-testindices]
cvtest <- train[testindices]
cvtestclass <- train_class[testindices]
inner_cv_glmnet_fit <- glmnet(data.matrix(cvtrain),as.factor(cvtrainclass),family="multinomial", alpha = alpha,lambda=lambda_sequence)
valid_pred <- predict(inner_cv_glmnet_fit, data.matrix(cvtest), s = lambda_sequence, type = "response")
#check order of predictions
order_of_class <- attr(valid_pred,'dimnames')[[2]]
new_order <- c(which(order_of_class=='1'),which(order_of_class=='2'),which(order_of_class=='3'))
foldresult <- rbindlist(lapply(c(1:length(lambda_sequence)),function(x) { data.table(repl=i,fold=j,lambda=lambda_sequence[x],valid_pred[,new_order,x],result=cvtestclass)}))
cvresult[[iter]]=foldresult
iter=iter+1
}
}
cvresult <- rbindlist(cvresult)
cvresult$result <- convert(cvresult$result)
names(cvresult) <- c("repl", "fold", "lambda", "odd1", "oddX", "odd2", "result")
# creating actual targets for rps calculations
cvresult[,pred_id:=1:.N]
outcome_for_rps <- data.table::dcast(cvresult,pred_id~result,value.var='pred_id')
outcome_for_rps[,pred_id:=NULL]
outcome_for_rps[is.na(outcome_for_rps)]=0
outcome_for_rps[outcome_for_rps>0]=1
setcolorder(outcome_for_rps, c("odd1", "oddX", "odd2"))
# calculate RPS
cvresult <- cvresult[, RPS := calculate_rps(odd1, oddX, odd2, result), by = 1:nrow(cvresult)]
overall_results <- data.table(cvresult[,list(repl,fold,lambda,RPS)])
# summarize performance for each lambda
overall_results_summary <- overall_results[,list(RPS=mean(RPS)),list(repl,fold,lambda)]
# find best lambdas as in glmnet based on RPS
overall_results_summary <- overall_results_summary[,list(meanRPS=mean(RPS),sdRPS=sd(RPS)),list(lambda)]
overall_results_summary[,RPS_mean_lb := meanRPS - sdRPS]
overall_results_summary[,RPS_mean_ub := meanRPS + sdRPS]
cv_lambda_min <- overall_results_summary[which.min(meanRPS)]$lambda
semin <- overall_results_summary[lambda==cv_lambda_min]$RPS_mean_ub
cv_lambda.1se <- max(overall_results_summary[meanRPS<semin]$lambda)
cvResultsSummary = list(lambda.min =cv_lambda_min, lambda.1se = cv_lambda.1se,
meanRPS_min=overall_results_summary[lambda==cv_lambda_min]$meanRPS,
meanRPS_1se=overall_results_summary[lambda==cv_lambda.1se]$meanRPS)
}
fit <- glmnet(as.matrix(train),as.factor(train_class),family="multinomial", alpha = alpha,lambda=cvResultsSummary$lambda.min)
predicted_probabilities <- predict(fit, as.matrix(test), type = "response")
output_prob <- data.table(predicted_probabilities[,,])
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
fit$bestTune <- data.frame(lambda = fit$lambda)
return(list(fit, output_prob))
}
train_glmnetcr <- function(train, test, wide_test,
alpha=1,nlambda=50,nofReplications=2,
nFolds=10){
set.seed(1234)
train_class <- train$winner
train <- train[,-c("winner")]
# to set lambda parameter, cross-validation will be performed and lambda is selected based on RPS performance
cvindices <- generateCVRuns(train_class,nofReplications,nFolds,stratified=TRUE)
# first get lambda sequence for all data
glmnet_alldata <- glmnetcr(as.matrix(train), as.factor(train_class), alpha = alpha, nlambda=nlambda)
lambda_sequence <- glmnet_alldata$lambda
cvresult=vector('list',nofReplications*nFolds)
iter=1
for(i in 1:nofReplications) {
thisReplication=cvindices[[i]]
for(j in 1:nFolds){
testindices <- order(thisReplication[[j]])
cvtrain <- train[-testindices]
cvtrainclass <- train_class[-testindices]
cvtest <- train[testindices]
cvtestclass <- train_class[testindices]
inner_cv_glmnet_fit <- glmnetcr(data.matrix(cvtrain),as.factor(cvtrainclass), alpha = alpha,lambda=lambda_sequence)
valid_pred <- predict(inner_cv_glmnet_fit, data.matrix(cvtest), s = lambda_sequence, type = "prob")
#check order of predictions
#order_of_class <- attr(valid_pred,'dimnames')[[2]]
#new_order <- c(which(order_of_class=='1'),which(order_of_class=='2'),which(order_of_class=='3'))
foldresult <- rbindlist(lapply(c(1:length(lambda_sequence)),function(x) {
data.table(repl=i,fold=j,lambda=lambda_sequence[x],valid_pred$probs[,,x],result=cvtestclass)
}))
cvresult[[iter]]=foldresult
iter=iter+1
}
}
cvresult <- rbindlist(cvresult)
#cvresult$result <- convert(cvresult$result)
#names(cvresult) <- c("repl", "fold", "lambda", "odd1", "oddX", "odd2", "result")
# creating actual targets for rps calculations
cvresult[,pred_id:=1:.N]
outcome_for_rps <- data.table::dcast(cvresult,pred_id~result,value.var='pred_id')
outcome_for_rps[,pred_id:=NULL]
outcome_for_rps[is.na(outcome_for_rps)]=0
outcome_for_rps[outcome_for_rps>0]=1
setcolorder(outcome_for_rps, c("odd1", "oddX", "odd2"))
# calculate RPS
cvresult <- cvresult[, RPS := calculate_rps(odd1, oddX, odd2, result), by = 1:nrow(cvresult)]
overall_results <- data.table(cvresult[,list(repl,fold,lambda,RPS)])
# summarize performance for each lambda
overall_results_summary <- overall_results[,list(RPS=mean(RPS)),list(repl,fold,lambda)]
# find best lambdas as in glmnet based on RPS
overall_results_summary <- overall_results_summary[,list(meanRPS=mean(RPS),sdRPS=sd(RPS)),list(lambda)]
overall_results_summary[,RPS_mean_lb := meanRPS - sdRPS]
overall_results_summary[,RPS_mean_ub := meanRPS + sdRPS]
cv_lambda_min <- overall_results_summary[which.min(meanRPS)]$lambda
semin <- overall_results_summary[lambda==cv_lambda_min]$RPS_mean_ub
cv_lambda.1se <- max(overall_results_summary[meanRPS<semin]$lambda)
cvResultsSummary = list(lambda.min =cv_lambda_min, lambda.1se = cv_lambda.1se,
meanRPS_min=overall_results_summary[lambda==cv_lambda_min]$meanRPS,
meanRPS_1se=overall_results_summary[lambda==cv_lambda.1se]$meanRPS)
fit <- glmnetcr(as.matrix(train),as.factor(train_class), alpha = alpha,lambda=cvResultsSummary$lambda.min)
predicted_probabilities <- predict(fit, data.matrix(test), type = "response")
output_prob <- data.table(predicted_probabilities[,,])
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
fit$bestTune <- data.frame(lambda = fit$lambda)
return(list(fit, output_prob))
}
gradient_boosting <- function(train, test, wide_test){
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = T,
summaryFunction = rpsCaret)
tune_Grid <-  expand.grid(interaction.depth = c(1,3,5),
n.trees = (1:10)*50,
shrinkage = c(0.01, 0.05, 0.1),
n.minobsinnode = c(5,10))
#plot(tune_Grid) #Error in plot.new() : figure margins too large
#plot(gbmFit, plotType = "level")
set.seed(1234)
fit <- train(winner ~ .,
data = train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = tune_Grid)
output_prob <- predict(fit, test, "prob")
#colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
return(list(fit, output_prob))
}
decision_tree <- function(train, test, wide_test){
set.seed(1234)
fit <-  train(y = train$winner,
x = train[,-c("winner")],
method = "rpart",
tuneGrid = expand.grid(.cp = c((1:7)*0.03)),
trControl = trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = T,
summaryFunction = rpsCaret))
output_prob <- predict(fit, test, "prob")
#colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
return(list(fit, output_prob))
}
vglmCumulative <- function(train, test, wide_test){
set.seed(1234)
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = TRUE,
savePredictions = T)
tunegrid <- expand.grid(parallel = TRUE, link = c("logit", "probit"))
fit <- train(winner~.,
data=train,
method="vglmCumulative",
trControl=control,
importance = T)
output_prob <- predict(fit, test, "prob")
colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
return(list(fit, output_prob))
}
best_model <- function(train, test, wide_test, best_name){
if(best_name == "gradient_boosting"){
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
classProbs = T,
summaryFunction = rpsCaret)
tune_Grid <-  expand.grid(interaction.depth = 1,
n.trees = c(200),
shrinkage = 0.01,
n.minobsinnode = 5)
set.seed(1234)
fit <- train(winner ~ .,
data = train,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
tuneGrid = tune_Grid)
}
if(best_name == "decision_tree"){
set.seed(1234)
fit <-  train(y = train$winner,
x = train[,-c("winner")],
method = "rpart",
tuneGrid = expand.grid(.cp = c(0.06)),
trControl = trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = T,
summaryFunction = rpsCaret))
}
if(best_name == "random_forest"){
set.seed(1234)
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
search = "grid",
classProbs = TRUE,
summaryFunction = rpsCaret)
tunegrid <- expand.grid(.mtry= 4.5)
fit <- train(winner~.,
data=train,
method="rf",
tuneGrid=tunegrid,
trControl=control,
importance = T)
}
output_prob <- predict(fit, test, "prob")
#colnames(output_prob) <- c("odd1", "oddX", "odd2")
output_prob$matchId <- wide_test$matchId
setcolorder(output_prob, c("matchId", "odd1", "oddX", "odd2"))
output_prob <- comparison(output_prob, trace = T)
return(list(fit, output_prob))
}
odd_strategy <- function(output_prob){
play <- output_prob[oddX > 0.30][odd2 < 0.315]
table(play$winner)
best_bookmaker <- "Pinnacle"
portfolio_df <- lastrps[bookmaker == best_bookmaker][matchId %in% play$matchId][,c(1,3,4,5)]
#portfolio_df <- shin_changes[bookmaker == best_bookmaker][matchId %in% play$matchId]
odds <- details[bookmaker == "Pinnacle"][matchId %in% play$matchId]
key(odds) <- c("matchId", "oddtype")
last_odds <- odds[unique(odds[,key(odds), with = FALSE]), mult = 'all']
last_oddsX <- last_odds[oddtype == "oddX"]
reshape(last_odds, idvar = c("bookmaker", "matchId"), timevar = "oddtype", direction = "wide" )
View(merge(next_matches[,c(1,3,4)], play, by = "matchId")[,c(1:6)])
final <- merge(play, last_oddsX, by = "matchId")
final <- merge(final, portfolio_df, by = "matchId")
final <- final[,c(1,2,3,4,10,12,11,5,9)]
final$initial <- 10
final$onhand <- 0
final$cumulative <- 0
final$net <- 0
if (final$winner[1] == "oddX"){
final$onhand[1] <- final$odd[1] * 10
final$cumulative[1] <- final$onhand[1]
}
for (i in (2:nrow(final))){
if (final$winner[i] == "oddX"){
final$onhand[i] <- final$odd[i] * 10
}
final$cumulative[i] <- final$onhand[i] + final$cumulative[i-1]
}
for (i in (1:nrow(final))){
final$net[i] <- final$cumulative[i] - i * 10
}
View(final)
#tree_fit <- train(winner ~ ., as.matrix(final[,c(2:9)]), "rpart")
plot_ly(x = 1:nrow(final), y = final$net, name = "Cumulative Net Gain", type = "scatter", mode = "lines+markers") %>%
add_trace(y = final$onhand, name = 'On Hand Money', mode = 'markers') %>%
layout(title = '2017-2018 Season Odd Strategy',
yaxis = list(title = 'Gain'),
xaxis = list(title = 'Match Number'))
return(final)
}
f <- data.frame(ModelName = "Decision Tree",
TrainSeason = "Overall",
Test = "2018-2019 Season",
RPS = 0.179217)
fit <- train_glmnet(train, test, wide_test)
fit <- decision_tree(train, test, wide_test)
fit
fit <- train_glmnet(train, test, wide_test)
fit
