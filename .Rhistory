library(readr)
CDNOW_master <- read_csv("Downloads/CDNOW_master/CDNOW_master.txt")
View(CDNOW_master)
cdnow <- read.table("Downloads/CDNOW_master/CDNOW_master.txt")
rm(CDNOW_master)
View(cdnow)
cdnow$V1 <- NULL
View(cdnow)
colnames(cdnow) <- c(“ID”, “TARIH”, “ADET”, “FIYAT”)
cdnow <- read.table("Downloads/CDNOW_master/CDNOW_master.txt")
colnames(cdnow) <- c(“ID”, “TARIH”, “ADET”, “FIYAT”)
View(cdnow)
colnames(cdnow) <- c("ID", "TARIH", "ADET", "FIYAT")
View(cdnow)
str(cdnow)
cdnow$ID <- as.factor(as.character(cdnow$ID))
cdnow$TARIH <- as.Date(as.character(cdnow$TARIH), “%Y%m%d”)
cdnow$TARIH <- as.Date(as.character(cdnow$TARIH), "%Y%m%d")
str(cdnow)
refDay <- max(cdnow$TARIH)
class(refDay)
as.numeric(refDay — cdnow$TARIH)
as.numeric(refDay-cdnow$TARIH)
library(dplyr)
rfm_recency <- cdnow %>% group_by(ID) %>% summarise(Recency = as.numeric(refDay)—as.numeric(max(TARIH)))
rfm_recency <- cdnow %>% group_by(ID) %>% summarise(Recency = as.numeric(refDay)—as.numeric(max(TARIH)))
rfm_recency <- cdnow %>% group_by(ID) %>% summarise(Recency = as.numeric(refDay)-as.numeric(max(TARIH)))
View(rfm_recency)
rfm_frequency <- cdnow %>% group_by(ID) %>% summarise(Frequency = n())
View(rfm_frequency)
rfm_monetary <- cdnow %>% group_by(ID) %>% summarise(Monetary = sum(FIYAT))
View(rfm_monetary)
cdnow$ID == 1
cdnow[cdnow$ID == 1]
cdnow[cdnow$ID == 1]
filter(cdnow, ID == 1)
filter(cdnow, ID == 951)
filter(rfm_monetary, ID == 951)
install.packages("mlr")
install.packages("XML")
### clears the environment
rm(list = ls())
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
### clears the environment
rm(list = ls())
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
library(plotly)
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### sets directory easily
# 1 - set_directory(name)
# name can be "mert", "emre", "mert_data", "emre_data"
source("set_directory.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
### implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
source("rps.R")
### converting dates to seasons
# functions in this file:
# 1 - season_calc(date)
source("season_calculator.R")
### converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
source("converter.R")
### read and prepare dataframes (not ready)
# 1 - details (matchId, bookmaker, oddtype, odd)
# 2 - matches (matchId, score, home, away, date, over_under, winner, season)
# 3 - first (matchId, bookmaker, oddtype, odd)
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
source("get_dataframes.R")
### handle missing odds and subsetting data
#
source("missingvalues.R")
### converting odds to basic and shin probabilities
# changes first and last dataframes
source("convert_odds.R")
#widening first and last for feature extraction
first_copy <- copy(first)
#bookiesToKeep = c("10Bet", "12BET", "188BET", "BetVictor", "Betclic", "Betsafe", "Betsson", "Betway", "Pinnacle", "SBOBET", "Unibet", "WilliamHill", "bet365", "betathome", "bwin")
#bookiesToKeep = c("10Bet", "188BET", "Pinnacle")
subsetBookies <- function(arr, df){
df <- df[bookmaker %in% arr]
df
}
subsetBookies(c("1xBet", "188BET", "Pinnacle"), first_copy)
first_copy <- subsetBookies(c("1xBet", "188BET", "Pinnacle"), first_copy)
first
#widening first and last for feature extraction
widening <- function(arr){
first_copy <- copy(first)
first_copy <- subsetBookies(arr, first_copy)
last_copy <- copy(last)
last_copy <- subsetBookies(arr, last_copy)
wide_first <- reshape(first_copy[,-4], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_first <- reshape(wide_first, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_first <- merge(wide_first, matches[, .(matchId, winner, date, week, season)], by = "matchId")
wide_last <- reshape(last_copy[,-4], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_last <- reshape(wide_last, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_last <- merge(wide_last, matches[, .(matchId, winner, date, week, season)], by = "matchId")
}
widening(c("1xBet", "188BET", "Pinnacle"))
wide_first
arr = c("1xBet", "188BET", "Pinnacle")
first_copy <- copy(first)
first_copy <- subsetBookies(arr, first_copy)
last_copy <- copy(last)
last_copy <- subsetBookies(arr, last_copy)
wide_first <- reshape(first_copy[,-4], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_first <- reshape(wide_first, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_first <- merge(wide_first, matches[, .(matchId, winner, date, week, season)], by = "matchId")
wide_last <- reshape(last_copy[,-4], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_last <- reshape(wide_last, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_last <- merge(wide_last, matches[, .(matchId, winner, date, week, season)], by = "matchId")
first
df_copy[,-4]
first[,-4]
first[,-"norm_prob"]
#widening first and last for feature extraction
widening <- function(df, arr){
df_copy <- copy(df)
df_copy <- subsetBookies(arr, df_copy)
df_wide <- reshape(df_copy[,-"norm_prob"], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
df_wide <- reshape(df_wide, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
df_wide <- merge(df_wide, matches[, .(matchId, winner, date, week, season)], by = "matchId")
df_wide
}
### clears the environment
rm(list = ls())
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
library(plotly)
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### sets directory easily
# 1 - set_directory(name)
# name can be "mert", "emre", "mert_data", "emre_data"
source("set_directory.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
### implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
source("rps.R")
### converting dates to seasons
# functions in this file:
# 1 - season_calc(date)
source("season_calculator.R")
### converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
source("converter.R")
### read and prepare dataframes (not ready)
# 1 - details (matchId, bookmaker, oddtype, odd)
# 2 - matches (matchId, score, home, away, date, over_under, winner, season)
# 3 - first (matchId, bookmaker, oddtype, odd)
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
source("get_dataframes.R")
### handle missing odds and subsetting data
#
source("missingvalues.R")
### converting odds to basic and shin probabilities
# changes first and last dataframes
source("convert_odds.R")
next_matches
matches
next_matches$score[1]
is.na(next_matches$score[1])
is.na(matches$score[1])
is.na(matches$score)
is.na(any(matches$score))
is.na(matches$score)
which(is.na(matches$score))
### reshaping first and last dataframes to feature extraction
# 1 - wide_first (matchId, shin*basic*bookmaker*oddtype, winner)
# 2 - wide_last (matchId, shin*basic*bookmaker*oddtype, winner)
source("reshape.R")
wide_first <- widening(first, c("1xBet", "188BET", "Pinnacle"))
View(wide_first)
wide_first <- widening(first, c("188BET", "Pinnacle"))
wide_last <- widening(last, c("188BET", "Pinnacle"))
### calculate RPS for all matches using Basic and Shin probs
# changes in first and last dataframes
source("calculate_rps.R")
### calculate average RPS for all bookmakers using Basic and Shin probs
source("bookmaker_comparison.R")
### calculate average RPS for all bookmakers using Basic and Shin probs
source("bookmaker_comparison.R")
average
# or
train_features <- wide_last[season != "2018-2019"]
test_features <- wide_last[season == "2018-2019"]
train_features
n <- ncol(train_features)
not_included_feature_indices = c(1,n-3,n-2,n-1,n)
not_included_feature_indices
### construction of model (not ready)
# functions in this file:
# 1 - train_glmnet
source("train_models.R")
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions <- train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T,max=FALSE)
predictions
predict <- predictions[["predictions"]]
predict <- predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS <- mean(predict$RPS)
averageRPS
testRPS <- last[matchId %in% predict$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
testRPS
