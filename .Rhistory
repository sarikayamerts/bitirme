setwd("/Users/mertsarikaya/bitirme/")
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
library(plotly)
testStart=as.Date('2017-07-15')
trainStart=as.Date('2010-08-13')
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
### implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
source("rps.R")
### converting dates to seasons
# functions in this file:
# 1 - season_calc(date)
source("season_calculator.R")
### converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
source("converter.R")
### read and prepare dataframes (not ready)
# 1 - details (matchId, bookmaker, oddtype, odd)
# 2 - matches (matchId, score, home, away, date, over_under, winner, season)
# 3 - first (matchId, bookmaker, oddtype, odd)
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
source("get_dataframes.R")
### handle missing odds
#
source("missingvalues.R")
### converting odds to basic and shin probabilities
# changes first and last dataframes
source("convert_odds.R")
### reshaping first and last dataframes to feature extraction
# 1 - wide_first (matchId, shin*basic*bookmaker*oddtype, winner)
# 2 - wide_last (matchId, shin*basic*bookmaker*oddtype, winner)
source("reshape.R")
### calculate RPS for all matches using Basic and Shin probs
# changes in first and last dataframes
source("calculate_rps.R")
### calculate average RPS for all bookmakers using Basic and Shin probs
source("bookmaker_comparison.R")
### Creating training and test data
train_features <- wide_last[date>=trainStart & date<testStart]
test_features <- wide_last[date>=testStart]
not_included_feature_indices = c(1,11,12,13,14)
### construction of model (not ready)
# functions in this file:
# 1 - train_glmnet
source("train_models.R")
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
predict = predictions[["predictions"]]
predict
predict = predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
predict
predict
averageRPS = mean(predict$RPS)
average
averageRPS
average_season
View(average_season)
### clears the environment
rm(list = ls())
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
library(plotly)
testStart=as.Date('2017-07-15')
trainStart=as.Date('2010-08-13')
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
set_directory <- function(name){
if (name == "mert_data"){
### mert's macbook database directory
setwd("/Users/mertsarikaya/Downloads/Bitirme/")
### emre's database directory
#setwd("C:/Users/Hp/Desktop/Bitirme")
}
else if (name == "emre_data"){
### emre's database directory
setwd("C:/Users/Hp/Desktop/Bitirme")
}
else if (name == "mert"){
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
}
else if (name == "emre"){
### emre's github directory
setwd("C:/Users/Hp/Desktop/Bitirme/bitirme")
}
}
set_directory("mert")
getwd()
set_directory("mert_data")
getwd()
set_directory("emre_data")
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
source("set_directory.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
### implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
source("rps.R")
### converting dates to seasons
# functions in this file:
# 1 - season_calc(date)
source("season_calculator.R")
### converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
source("converter.R")
### read and prepare dataframes (not ready)
# 1 - details (matchId, bookmaker, oddtype, odd)
# 2 - matches (matchId, score, home, away, date, over_under, winner, season)
# 3 - first (matchId, bookmaker, oddtype, odd)
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
source("get_dataframes.R")
### handle missing odds and subsetting data
#
source("missingvalues.R")
c("10Bet", "188BET", "Pinnacle")
arr2 <- c("10Bet", "188BET", "Pinnacle")
arr2
array(data = c("10Bet", "188BET"))
subsetBookies <- function(arr){
first = first[bookmaker %in% bookiesToKeep]
last = last[bookmaker %in% bookiesToKeep]
}
subsetBookies(c("10Bet", "188BET"))
subsetBookies <- function(arr){
first = first[bookmaker %in% arr]
last = last[bookmaker %in% arr]
}
subsetBookies(c("10Bet", "188BET"))
first
first[bookmaker %in% arr]
arr = c("10Bet", "188BET")
arr
first[bookmaker %in% arr]
subsetBookies <- function(arr){
first <<- first[bookmaker %in% arr]
last <<- last[bookmaker %in% arr]
}
subsetBookies(c("10Bet", "188BET"))
### handle missing odds and subsetting data
#
source("missingvalues.R")
### converting odds to basic and shin probabilities
# changes first and last dataframes
source("convert_odds.R")
### reshaping first and last dataframes to feature extraction
# 1 - wide_first (matchId, shin*basic*bookmaker*oddtype, winner)
# 2 - wide_last (matchId, shin*basic*bookmaker*oddtype, winner)
source("reshape.R")
### calculate RPS for all matches using Basic and Shin probs
# changes in first and last dataframes
source("calculate_rps.R")
### calculate average RPS for all bookmakers using Basic and Shin probs
source("bookmaker_comparison.R")
wide_first
average
### clears the environment
rm(list = ls())
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
library(plotly)
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### sets directory easily
# 1 - set_directory(name)
# name can be "mert", "emre", "mert_data", "emre_data"
source("set_directory.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
### implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
source("rps.R")
### converting dates to seasons
# functions in this file:
# 1 - season_calc(date)
source("season_calculator.R")
### converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
source("converter.R")
### read and prepare dataframes (not ready)
# 1 - details (matchId, bookmaker, oddtype, odd)
# 2 - matches (matchId, score, home, away, date, over_under, winner, season)
# 3 - first (matchId, bookmaker, oddtype, odd)
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
source("get_dataframes.R")
### handle missing odds and subsetting data
#
source("missingvalues.R")
### converting odds to basic and shin probabilities
# changes first and last dataframes
source("convert_odds.R")
### reshaping first and last dataframes to feature extraction
# 1 - wide_first (matchId, shin*basic*bookmaker*oddtype, winner)
# 2 - wide_last (matchId, shin*basic*bookmaker*oddtype, winner)
source("reshape.R")
### calculate RPS for all matches using Basic and Shin probs
# changes in first and last dataframes
source("calculate_rps.R")
### calculate average RPS for all bookmakers using Basic and Shin probs
source("bookmaker_comparison.R")
c(1,-1:-4)
wide_first
# glmnet works with complete data
glm_features <- train_features[complete.cases(train_features)]
wide_first
train_features <- wide_last[season == "2018-2019"]
train_features
train_features <- wide_last[season != "2018-2019"]
test_features <- wide_last[season == "2018-2019"]
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
### construction of model (not ready)
# functions in this file:
# 1 - train_glmnet
source("train_models.R")
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
not_included_feature_indices = c(1,-1:-4)
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
not_included_feature_indices = c("matchId")
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
not_included_feature_indices = c(1,44,43,42,41)
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
predict = predictions[["predictions"]]
predict = predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS = mean(predict$RPS)
averageRPS
average_season
View(average_season)
View(wide_last)
View(last)
View(details)
next_matches
# or
start = as.Date('2018-11-30')
end = as.Date('2018-12-02')
test_features <- wide_last[date >= start & date <= end]
test_features <- wide_last[date < start]
test_features <- wide_last[date >= start & date <= end]
train_features <- wide_last[date < start]
test_features
wide_last$date
train_features <- wide_last[date < start]
train_features
View(last)
last[season = "2018-2019"]
last[season == "2018-2019"]
unique(last[season == "2018-2019"]$week)
last[season == "2018-2019" & week = "47"]
last[season == "2018-2019" & week == "47"]
#widening first and last for feature extraction
wide_first <- reshape(first[,-4], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
wide_first <- reshape(wide_first, idvar = c("matchId"), timevar = c("bookmaker"), direction = "wide")
wide_first <- merge(wide_first, matches[, .(matchId, winner, date, week, season)], by = "matchId")
first
#widening first and last for feature extraction
wide_first <- reshape(first[,-4], idvar = c("matchId", "bookmaker"), timevar = c("oddtype"), direction = "wide")
### clears the environment
rm(list = ls())
### mert's macbook github directory
setwd("/Users/mertsarikaya/bitirme/")
library(readr)
library(graphics)
library(data.table)
library(verification)
library(glmnet)
library(TunePareto)
library(anytime)
library(plotly)
### implementation of shin probability calculation
# functions in this file:
# 1 - shin_prob_calculator(list)
source("shin.R")
### sets directory easily
# 1 - set_directory(name)
# name can be "mert", "emre", "mert_data", "emre_data"
source("set_directory.R")
### implementation of converting match results from string to {over, under, 1, X, 2} types of outcome
# functions in this file:
# 1 - winner(score)
# 2 - over_under(score)
# 3 - inverse(odd)
source("match_scores.R")
### implementation of ranked probability score
# functions in this file:
# 1 - calculate_rps(home, draw, away, actual)
# 2 - calculate_rps2(over, under, actual)
source("rps.R")
### converting dates to seasons
# functions in this file:
# 1 - season_calc(date)
source("season_calculator.R")
### converting odd1, oddX, odd2 to 1,2,3 and viceversa
# 1 - convert(arr)
source("converter.R")
### read and prepare dataframes (not ready)
# 1 - details (matchId, bookmaker, oddtype, odd)
# 2 - matches (matchId, score, home, away, date, over_under, winner, season)
# 3 - first (matchId, bookmaker, oddtype, odd)
# 4 - last (matchId, bookmaker, oddtype, odd)
# 5 - next_matches (matchId, score, home, away, date)
source("get_dataframes.R")
### handle missing odds and subsetting data
#
source("missingvalues.R")
### converting odds to basic and shin probabilities
# changes first and last dataframes
source("convert_odds.R")
### reshaping first and last dataframes to feature extraction
# 1 - wide_first (matchId, shin*basic*bookmaker*oddtype, winner)
# 2 - wide_last (matchId, shin*basic*bookmaker*oddtype, winner)
source("reshape.R")
### calculate RPS for all matches using Basic and Shin probs
# changes in first and last dataframes
source("calculate_rps.R")
### calculate average RPS for all bookmakers using Basic and Shin probs
source("bookmaker_comparison.R")
wide_last$date
wide_last$date < "2018-11-30"
# or
start = '2018-11-30'
end = '2018-12-02'
test_features <- wide_last[date >= start & date <= end]
train_features <- wide_last[date < start]
wide_last
View(wide_last)
# or
start = '2018-11-24'
end = '2018-11-26'
test_features <- wide_last[date >= start & date <= end]
train_features <- wide_last[date < start]
not_included_feature_indices = c(1,-1:-4)
not_included_feature_indices = c(1,44,43,42,41)
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
### construction of model (not ready)
# functions in this file:
# 1 - train_glmnet
source("train_models.R")
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
predict = predictions[["predictions"]]
predict
predict = predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS = mean(predict$RPS)
averageRPS
last
predict$matchId
last[matchId %in% predict$matchId]
last[matchId %in% predict$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- last[matchId %in% predict$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS[order(testRPS$var),]
averageRPS
testStart=as.Date('2017-07-15')
trainStart=as.Date('2010-08-13')
train_features <- wide_last[date>=trainStart & date<testStart]
test_features <- wide_last[date>=testStart]
not_included_feature_indices = c(1,-1:-4)
ncol(train_features)
testStart=as.Date('2017-07-15')
trainStart=as.Date('2010-08-13')
train_features <- wide_last[date>=trainStart & date<testStart]
test_features <- wide_last[date>=testStart]
n <- ncol(train_features)
not_included_feature_indices = c(1,n-3,n-2,n-1,n)
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions=train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
predict <- predictions[["predictions"]]
predict
predict <- predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS <- mean(predict$RPS)
averageRPS
testRPS <- last[matchId %in% predict$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
testRPS
last
# glmnet works with complete data
glm_features <- train_features[complete.cases(train_features)]
glm_features
glm_features$winner <- convert(glm_features$winner)
train_class <- as.numeric(glm_features$winner)
glm_train_data <- glm_features[,-not_included_feature_indices,with=F]
glm_test_data <- test_features[,-not_included_feature_indices,with=F]
glm_train_data
glm_train_data[,max(1:ncol(glm_train_data)), by = 1:nrow(glm_train_data)]
glm_train_data[,max(glm_train_data[1:ncol(glm_train_data)]), by = 1:nrow(glm_train_data)]
glm_train_data[1:ncol(glm_train_data)]
max(glm_train_data[1:ncol(glm_train_data)])
glm_train_data[,max(glm_train_data[1:ncol(glm_train_data)]), by = 1:nrow(glm_train_data)]
glm_train_data[, maximum_element := max(glm_train_data[1:ncol(glm_train_data)]), by = 1:nrow(glm_train_data)]
glm_train_data
names(glm_train_data)
# glmnet works with complete data
glm_features <- train_features[complete.cases(train_features)]
glm_features$winner <- convert(glm_features$winner)
train_class <- as.numeric(glm_features$winner)
glm_train_data <- glm_features[,-not_included_feature_indices,with=F]
glm_test_data <- test_features[,-not_included_feature_indices,with=F]
glm_train_data[, maximum_element := max(names(glm_train_data)), by = 1:nrow(glm_train_data)]
glm_train_data
apply(glm_train_data, 1, FUN=max)
glm_train_data
do.call(pmin, glm_test_data)
do.call(pmax, glm_test_data)
# glmnet works with complete data
glm_features <- train_features[complete.cases(train_features)]
glm_features$winner <- convert(glm_features$winner)
train_class <- as.numeric(glm_features$winner)
glm_train_data <- glm_features[,-not_included_feature_indices,with=F]
glm_test_data <- test_features[,-not_included_feature_indices,with=F]
apply(glm_train_data, 1, FUN=max)
glm_train_data$max <- do.call(pmax, glm_train_data)
glm_train_data$min <- do.call(pmin, glm_train_data)
glm_train_data
glm_test_data$max <- do.call(pmax, glm_test_data)
### construction of model (not ready)
# functions in this file:
# 1 - train_glmnet
source("train_models.R")
# or
train_features <- wide_last[season != "2018-2019"]
test_features <- wide_last[season == "2018-2019"]
n <- ncol(train_features)
not_included_feature_indices = c(1,n-3,n-2,n-1,n)
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions <- train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T)
predict <- predictions[["predictions"]]
predict <- predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS <- mean(predict$RPS)
averageRPS
testRPS <- last[matchId %in% predict$matchId][, .(var = mean(Shin_RPS, na.rm = TRUE)), by = c("bookmaker")]
testRPS <- testRPS[order(testRPS$var),]
testRPS
### construction of model (not ready)
# functions in this file:
# 1 - train_glmnet
source("train_models.R")
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions <- train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T,max=TRUE)
predict <- predictions[["predictions"]]
predict <- predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS <- mean(predict$RPS)
averageRPS
### Run glmnet on train data with tuning lambda parameter based on RPS and return predictions based on lambda with minimum RPS
predictions <- train_glmnet(train_features, test_features,not_included_feature_indices, alpha=1,nlambda=50, tune_lambda=TRUE,nofReplications=2,nFolds=10,trace=T,max=FALSE)
predict <- predictions[["predictions"]]
predict <- predict[, RPS := calculate_rps(odd1,oddX,odd2,winner), by = 1:nrow(predict)]
averageRPS <- mean(predict$RPS)
averageRPS
